{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe642d5e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you're in the 'owen' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapter.ipynb  \u001b[0m\u001b[38;5;27m__pycache__\u001b[0m/                 Terminal commands.txt\n",
      "\u001b[38;5;27mOptimus_dir\u001b[0m/   run_latent_generation.ipynb\n"
     ]
    }
   ],
   "source": [
    "# %cd ..\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "856ff2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, pipeline, AutoModelForCausalLM, Trainer, LlamaTokenizer\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del Optimus\n",
    "from Optimus_dir.code.Optimus import Optimus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cacdb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model name 'Optimus_dir/code/optimus_latent32_beta05/checkpoint-encoder-508523' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). We assumed 'Optimus_dir/code/optimus_latent32_beta05/checkpoint-encoder-508523' was a path or url but couldn't find any file associated to this path or url.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "file Optimus_dir/code/optimus_latent32_beta05/checkpoint-encoder-508523 not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/data/joshua_clymer/spar-red-team/owen/Adapter.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22636f6d707574652e736166652e6169222c2275736572223a226a6f736875615f636c796d6572227d/data/joshua_clymer/spar-red-team/owen/Adapter.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# initialize Optimus VAE\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22636f6d707574652e736166652e6169222c2275736572223a226a6f736875615f636c796d6572227d/data/joshua_clymer/spar-red-team/owen/Adapter.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m vae32 \u001b[39m=\u001b[39m Optimus(\u001b[39m'\u001b[39;49m\u001b[39mOptimus_dir/code/optimus_latent32_beta05\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m32\u001b[39;49m)\n",
      "File \u001b[0;32m~/spar-red-team/owen/Optimus_dir/code/Optimus.py:87\u001b[0m, in \u001b[0;36mOptimus.__init__\u001b[0;34m(self, checkpoint_dir, latent_size)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39m# Load a trained Encoder model and vocabulary that you have fine-tuned\u001b[39;00m\n\u001b[1;32m     86\u001b[0m encoder_config_class, encoder_model_class, encoder_tokenizer_class \u001b[39m=\u001b[39m Optimus\u001b[39m.\u001b[39mMODEL_CLASSES[args\u001b[39m.\u001b[39mencoder_model_type]\n\u001b[0;32m---> 87\u001b[0m model_encoder \u001b[39m=\u001b[39m encoder_model_class\u001b[39m.\u001b[39;49mfrom_pretrained(output_encoder_dir, latent_size\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mlatent_size)\n\u001b[1;32m     88\u001b[0m tokenizer_encoder \u001b[39m=\u001b[39m encoder_tokenizer_class\u001b[39m.\u001b[39mfrom_pretrained(args\u001b[39m.\u001b[39mencoder_tokenizer_name \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mencoder_tokenizer_name \u001b[39melse\u001b[39;00m args\u001b[39m.\u001b[39mencoder_model_name_or_path, do_lower_case\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mdo_lower_case)\n\u001b[1;32m     89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer_encoder \u001b[39m=\u001b[39m tokenizer_encoder\n",
      "File \u001b[0;32m~/spar-red-team/owen/Optimus_dir/code/pytorch_transformers/modeling_utils.py:287\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39m# Load config\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[39mif\u001b[39;00m config \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 287\u001b[0m     config, model_kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mconfig_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    288\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args,\n\u001b[1;32m    289\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir, return_unused_kwargs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    290\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    291\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    292\u001b[0m     )\n\u001b[1;32m    293\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    294\u001b[0m     model_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/spar-red-team/owen/Optimus_dir/code/pytorch_transformers/configuration_utils.py:144\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m         logger\u001b[39m.\u001b[39merror(\n\u001b[1;32m    138\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mModel name \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m was not found in model name list (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mWe assumed \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m was a path or url but couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find any file \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mpretrained_config_archive_map\u001b[39m.\u001b[39mkeys()),\n\u001b[1;32m    143\u001b[0m                 config_file))\n\u001b[0;32m--> 144\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m resolved_config_file \u001b[39m==\u001b[39m config_file:\n\u001b[1;32m    146\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mloading configuration file \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(config_file))\n",
      "File \u001b[0;32m~/spar-red-team/owen/Optimus_dir/code/pytorch_transformers/configuration_utils.py:130\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39m# redirect to the cache, if necessary\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_path(config_file, cache_dir\u001b[39m=\u001b[39;49mcache_dir, force_download\u001b[39m=\u001b[39;49mforce_download, proxies\u001b[39m=\u001b[39;49mproxies)\n\u001b[1;32m    131\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    132\u001b[0m     \u001b[39mif\u001b[39;00m pretrained_model_name_or_path \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mpretrained_config_archive_map:\n",
      "File \u001b[0;32m~/spar-red-team/owen/Optimus_dir/code/pytorch_transformers/file_utils.py:152\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39mreturn\u001b[39;00m url_or_filename\n\u001b[1;32m    150\u001b[0m \u001b[39melif\u001b[39;00m parsed\u001b[39m.\u001b[39mscheme \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    151\u001b[0m     \u001b[39m# File, but it doesn't exist.\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mfile \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(url_or_filename))\n\u001b[1;32m    153\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[39m# Something unknown\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munable to parse \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m as a URL or as a local path\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(url_or_filename))\n",
      "\u001b[0;31mOSError\u001b[0m: file Optimus_dir/code/optimus_latent32_beta05/checkpoint-encoder-508523 not found"
     ]
    }
   ],
   "source": [
    "# initialize Optimus VAE\n",
    "vae32 = Optimus('Optimus_dir/code/optimus_latent32_beta05', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 3 tokens to GPT2\n"
     ]
    }
   ],
   "source": [
    "vae = Optimus('Optimus_dir/code/optimus_latent768_beta05', 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_beta1 = Optimus('Optimus_dir/code/optimus_latent768_beta1', 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283\n",
      "He was selected 21st overall by the San Diego Padres in the 2004 amateur draft and received his first major league footy starting at shortstop, where he batted.306, hitting.385 with five home runs, 38 RBI and 67 runs scored.\n",
      "After coaching for the Minnesota Lynx of the National Basketball Association, Hanley competed for his college club in the 2014 NCAA tournament, appearing in four seasons with the Orlando Magic, Chicago Bulls and Philadelphia 76ers.\n",
      "In 1996, he started as a guard and enrolled in Georgia Southern University, where he quickly transferred to defensive backs at the start of the 1997 season, where he played his freshman season of 2008, helping Georgia Southern upset Georgia Tech 19–7.\n",
      "Columns and other major professional leagues was filled by Filipino draft choice Rodolfo Francisco, who was drafted by Kenosha High School in the 4th round (32nd overall) of the 1985 USA National League, where he played his first professional baseball as a puncher in 1998.\n",
      "In 1985, he made his senior season with the Dodgers, playing a 37 inning game, beginning with a 20-game disabled list in Game 1 against the Boston Red Sox, with a minor league managerial working as head coach.\n",
      "In early 1977, he was selected as pro prospect/big box head coach in Texas, where he helped Stan Herrmann lead the Texas Longhorns to six straight FCSA Awards; twice, he led the Longhorns to the inaugural national championship 2002 and then tied for eighth with the Boston Bruins in 2003.\n",
      "He made his NFL debut during the 1978 season as an undrafted free agent for the Detroit Lions, becoming 53-year-old 2013 seventh round draft pick of the Detroit Lions, and playing in seven games for the Detroit Lions during the 1978 season.\n",
      "He played his first professional college game as a professional, joining Oregon as a rookie, returning from his ACL injury in 2003–04, and later becoming the Ducks' starting quarterback in 2009–10.\n",
      "He played college hockey with the Vancouver Canucks, where he tied for the league lead with five points (in just his second NHL season) in phenom number two prodigy Anders Nilsson, a veteran whose career started in 1995-96 in the Swedish Hockey League.\n",
      "In 2001, with the Toronto Maple Leafs, the 9th overall pick by the Pittsburgh Penguins in the 1996 NHL Entry Draft of the Maple Leafs made his first NHL appearance, for a hometown club in a 7–1 series win over the Bruins, as a defense member of the Chicago Red Wings.\n"
     ]
    }
   ],
   "source": [
    "# Test optimus\n",
    "text_original = \"After playing college basketball for the LSU Tigers, O'Neal was drafted by the Orlando Magic with the first overall pick in the 1992 NBA draft. He quickly became one of the best centers in the league, winning Rookie of the Year in 1992–93 and leading his team to the 1995 NBA Finals.\"\n",
    "latent, code = vae.latent_code_from_text(text_original)\n",
    "print(len(text_original))\n",
    "# text = vae.text_from_latent_code(latent)\n",
    "for i in range(10):\n",
    "    print(vae.text_from_latent_code(latent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698ceef2",
   "metadata": {},
   "source": [
    "Load model\n",
    "\n",
    "- 9.3s with 5cpus 0gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79733575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name_or_path = \"ehartford/Wizard-Vicuna-30B-Uncensored\"\n",
    "# model_name_or_path = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "# model_name_or_path = \"EleutherAI/pythia-410m\"\n",
    "model_name_or_path = \"openlm-research/open_llama_3b_v2\"\n",
    "# model_name_or_path = \"EleutherAI/pythia-1.4b\"\n",
    "# !huggingface-cli login\n",
    "# model_name_or_path = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path, device_map=\"auto\")\n",
    "# model.to(torch.float16)\n",
    "# use_fast_tokenizer = \"LlamaForCausalLM\" not in model.config.architectures\n",
    "use_fast_tokenizer = True #OpenLlama v2 docs says use LlamaTokenizer directly\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=use_fast_tokenizer, padding_side=\"left\", legacy=False)\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name_or_path, use_fast=use_fast_tokenizer)\n",
    "# tokenizer.pad_token_id = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bfc2a0",
   "metadata": {},
   "source": [
    "Test model\n",
    "\n",
    "- 21.2s for 5cpus 0 gpus(max new tokens = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf03b5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Q: What is the largest country?\n",
      "A: The largest country is Russia.\n",
      "Q: What is the smallest country?\n",
      "A: The smallest country is Vatican City.\n",
      "Q: What is\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Q: What is the largest country?\\nA:'\n",
    "# tokenizer, model = accelerator.prepare(tokenizer, model)\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids, max_new_tokens=32\n",
    ")\n",
    "print(tokenizer.decode(generation_output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef25cb28",
   "metadata": {},
   "source": [
    "Load and check dataset (mini pile)\n",
    "- 1.2s with 5cpu 0 gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d7dd5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 10000\n",
      "})\n",
      "It is done, and submitted. You can play “Survival of the Tastiest” on Android, and on the web. Playing on the web works, but you have to simulate multi-touch for table moving and that can be a bit con\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"NeelNanda/pile-10k\", split=\"train\").remove_columns(\"meta\")\n",
    "print(dataset)\n",
    "print(dataset[0]['text'][:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b9bfe8",
   "metadata": {},
   "source": [
    "Initialize adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0a70f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model class for adapter, should just be a linear from dim of VAE latent to \n",
    "# class Adapter(nn.Linear):\n",
    "#     def __init__(self, d_in, d_out):\n",
    "#         super().__init__()\n",
    "        \n",
    "\n",
    "#     def forward(self, tokens: Int[Tensor, \"batch position\"]) -> Float[Tensor, \"batch position d_vocab\"]:\n",
    "#         return \n",
    "d_vae_latent = 32 # Latent size, could also be 768\n",
    "d_lm_embedding = model.config.hidden_size\n",
    "adapter = nn.Linear(d_vae_latent, d_lm_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ffe361",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdapterTrainer(Trainer):\n",
    "    def __init__(self, vae, lm):\n",
    "        # Trainer for an adapter from vae to lm\n",
    "        super().__init__()\n",
    "        self.vae = vae\n",
    "        self.lm = lm\n",
    "\n",
    "    def vae_encode(self, inputs):\n",
    "        latent_z, coded_length = self.vae.latent_code_from_text(inputs,)\n",
    "        return latent_z\n",
    "\n",
    "    def lm_hidden(self, text = None, vec = None):\n",
    "        '''\n",
    "        Returns the hidden full state of the LLM given either text or a vector\n",
    "        Hidden state is a tuple of FloatTensors, one for each hidden layer (including embedding)\n",
    "        Only confirmed to work for Llama architecture (incl OpenLlama)\n",
    "        '''\n",
    "        if text is not None:\n",
    "\n",
    "            return self.lm(input_ids = text, output_hidden_states=True, return_dict=True).hidden_states\n",
    "        elif vec is not None:\n",
    "            \n",
    "            return self.lm(inputs_embeds=vec, output_hidden_states=True, return_dict=True).hidden_states\n",
    "        else:\n",
    "            raise ValueError(\"Must provide either text or vec\")\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "\n",
    "        #1. Get VAE-encoded input\n",
    "        vae_encoded_inputs = self.vae_encode(inputs)\n",
    "        \n",
    "        #2. Pass VAE latent vector into adapter (get \"output\" from \"model\")\n",
    "        outputs = model(**vae_encoded_inputs)\n",
    "        \n",
    "        #3. Get hidden state of LM using adapter output as input\n",
    "        hidden_state_from_adapter = self.lm_hidden(vec = outputs) \n",
    "\n",
    "        #4. Pass the same text into LLM and get hidden state\n",
    "        hidden_state_from_text = self.lm_hidden(text = inputs)\n",
    "        \n",
    "        #5. Compute loss with cosine similarity between hidden states \n",
    "        loss = nn.functional.cosine_similarity(hidden_state_from_adapter, hidden_state_from_text) \n",
    "        # I think need to make sure hidden states are both 1d vectors\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer and run loop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "display-red-team",
   "language": "python",
   "name": "red-team"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
